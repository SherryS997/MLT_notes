<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MLT Notes - Support Vector Machines</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Support Vector Machines</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">MLT Notes</a> 
        <div class="sidebar-tools-main">
    <a href="https://www.linkedin.com/in/sherry-thomassp/" title="" class="sidebar-tool px-1"><i class="bi bi-linkedin"></i></a>
    <a href="https://github.com/SherryS997/MLT_notes" title="" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Home</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Content</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../about.html" class="sidebar-item-text sidebar-link">About</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Notes</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk01.html" class="sidebar-item-text sidebar-link">Week-01</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk02.html" class="sidebar-item-text sidebar-link">Week-02</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk03.html" class="sidebar-item-text sidebar-link">Week-03</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk04.html" class="sidebar-item-text sidebar-link">Week-04</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk05.html" class="sidebar-item-text sidebar-link">Week-05</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk06.html" class="sidebar-item-text sidebar-link">Week-06</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk07.html" class="sidebar-item-text sidebar-link">Week-07</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk08.html" class="sidebar-item-text sidebar-link">Week-08</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk09.html" class="sidebar-item-text sidebar-link">Week-09</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk10.html" class="sidebar-item-text sidebar-link active">Week-10</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#perceptron-and-margins" id="toc-perceptron-and-margins" class="nav-link active" data-scroll-target="#perceptron-and-margins">Perceptron and Margins</a>
  <ul class="collapse">
  <li><a href="#margin-maximization" id="toc-margin-maximization" class="nav-link" data-scroll-target="#margin-maximization">Margin Maximization</a></li>
  </ul></li>
  <li><a href="#constrained-optimization" id="toc-constrained-optimization" class="nav-link" data-scroll-target="#constrained-optimization">Constrained Optimization</a></li>
  <li><a href="#formulating-the-dual-problem" id="toc-formulating-the-dual-problem" class="nav-link" data-scroll-target="#formulating-the-dual-problem">Formulating the Dual Problem</a></li>
  <li><a href="#support-vector-machine" id="toc-support-vector-machine" class="nav-link" data-scroll-target="#support-vector-machine">Support Vector Machine</a>
  <ul class="collapse">
  <li><a href="#hard-margin-svm-algorithm" id="toc-hard-margin-svm-algorithm" class="nav-link" data-scroll-target="#hard-margin-svm-algorithm">Hard-Margin SVM Algorithm</a></li>
  </ul></li>
  <li><a href="#soft-margin-svm" id="toc-soft-margin-svm" class="nav-link" data-scroll-target="#soft-margin-svm">Soft-Margin SVM</a></li>
  <li><a href="#credits" id="toc-credits" class="nav-link" data-scroll-target="#credits">Credits</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Support Vector Machines</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>PDF Link: <a href="../notes/Wk10.pdf">notes</a></p>
<section id="perceptron-and-margins" class="level1">
<h1>Perceptron and Margins</h1>
<p>Let dataset <span class="math inline">\(D=\{(x_1, y_1), \ldots, (x_n,y_n)\}\)</span> be linearly separable with <span class="math inline">\(\gamma\)</span>-margin where <span class="math inline">\(x_i \in \mathbb{R}^d\)</span> and <span class="math inline">\(y_i \in \{-1, 1\}\)</span>.</p>
<p>Let <span class="math inline">\(w* \in \mathbb{R}^d\)</span> be the weight vector s.t. <span class="math inline">\((w^{*T}x_i)y_i\ge\gamma\)</span> <span class="math inline">\(\forall i\)</span>.</p>
<p>Let some <span class="math inline">\(R&gt;0 \in \mathbb{R}\)</span>, s.t. <span class="math inline">\(\forall i\)</span> <span class="math inline">\(||x_i||\le R\)</span>.</p>
<p>Therefore, the number of mistakes made by the algorithm is given by, <span class="math display">\[
\text{\#mistakes} \le \frac{R^2}{\gamma^2}
\]</span></p>
<p><strong>Observations</strong></p>
<p>Let <span class="math inline">\(w_{perc}\)</span> be any weight vector which can linearly separate the dataset.</p>
<p>Therefore, we observe the following:</p>
<ol type="1">
<li>“Quality” of the solution depends on the margin.</li>
<li>Number of mistakes depend on <span class="math inline">\(w^*\)</span>’s margin.</li>
<li><span class="math inline">\(w_{perc}\)</span> need not necessarily be <span class="math inline">\(w^*\)</span>.</li>
</ol>
<p>Hence, our <strong>goal</strong> should be to <strong>find the solution that maximizes the margin</strong>.</p>
<section id="margin-maximization" class="level2">
<h2 class="anchored" data-anchor-id="margin-maximization">Margin Maximization</h2>
<p>From the previous analysis, it is clear that a single dataset could have multiple linear classifiers with varying margins. The following diagram illustrates this phenomenon,</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/Multple possible classifiers.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Multiple Classifiers</figcaption><p></p>
</figure>
</div>
<p>Therefore, for getting the best classifier, our goal can be written as, <span class="math display">\[
\max_{w,\gamma} \gamma
\]</span> <span class="math display">\[\begin{align*}
s.t. (w^Tx_i)y_i &amp;\ge \gamma \hspace{1em} \forall i \\
||w||^2 &amp;= 1\
\end{align*}\]</span>\end{align*} The boundary of the margin is given by, <span class="math display">\[\begin{align*}
\{x:(w^Tx_i)y_i &amp;= \gamma\}\\
\{x:(\frac{w}{\gamma}^Tx_i)y_i &amp;= 1\}\\
\end{align*}\]</span> From the above equation, we can see that <span class="math inline">\(\gamma\)</span> depends on the width of <span class="math inline">\(w\)</span>. Therefore, we reformulate our goal as, <span class="math display">\[
\max_{w} \text{width}(w)
\]</span> <span class="math display">\[\begin{align*}
s.t. (w^Tx_i)y_i &amp;\ge 1 \hspace{1em} \forall i \\
\end{align*}\]</span> Let the width be the distance between the two parallel margins, and let <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span> be two points who are on the two lines exactly opposite to each other s.t. <span class="math inline">\(w^Tx=-1\)</span> and <span class="math inline">\(w^Tz=1\)</span> or vice versa.</p>
<p>Let <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> be two points which lie on opposite side of the decision boundary as well as on the margins.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/Perceptron Distance.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Margin Width</figcaption><p></p>
</figure>
</div>
<p>Therefore, the width is given by, <span class="math display">\[\begin{align*}
||x_1^Tw - x_2^Tw||_2^2 &amp;= 2 \\
||x_1-x_2||_2^2||w||^2_2 &amp;= 2\\
\therefore ||x_1 - x_2||^2_2 &amp;= \frac{2}{||w||^2_2}
\end{align*}\]</span></p>
<p>Therefore, our objective function can be written as, <span class="math display">\[
\max_{w}  \frac{2}{||w||^2_2} \hspace{1em} s.t. (w^Tx_i)y_i \ge 1 \hspace{1em} \forall i
\]</span> Equivalently, <span class="math display">\[
\min_{w}  \frac{1}{2}||w||^2_2 \hspace{1em} s.t. (w^Tx_i)y_i \ge 1 \hspace{1em} \forall i
\]</span> Therefore ﬁnding the separating hyperplane with maximum margin is equivalent to ﬁnding the one with the smallest possible normal vector <span class="math inline">\(w\)</span>.</p>
</section>
</section>
<section id="constrained-optimization" class="level1">
<h1>Constrained Optimization</h1>
<p>Let a constrained optimization problem be formulated as follows, <span class="math display">\[\begin{align*}
\min_w f(w) \\
s.t. g(w) \le 0 \\
\end{align*}\]</span> We can solve this problem using <strong>Lagrange Multipliers</strong>.</p>
<p>Lagrange multipliers are used in constrained optimization problems to find the optimal values of the objective function subject to a set of constraints. In Lagrange multipliers method, the constraints are incorporated into the objective function by introducing additional variables called Lagrange multipliers.</p>
<p>The Lagrange function <span class="math inline">\(\mathcal{L}(x, \alpha)\)</span>, for our above function, is defined as follows: <span class="math display">\[
\mathcal{L}(w, \alpha) = f(w) + \alpha g(w) \hspace{1em} \forall w
\]</span> where <span class="math inline">\(\alpha \ge 0\)</span>.</p>
<p>Therefore, maximizing the Lagrange function w.r.t. <span class="math inline">\(\alpha\)</span>, <span class="math display">\[\begin{align*}
\max_{\alpha\ge0} \mathcal{L}(w, \alpha) &amp;= \max_{\alpha\ge0} f(w) + \alpha g(w) \\
&amp;=
\begin{cases}
\infty \hspace{2em} \text{if} \hspace{1em} g(w) &gt; 0 \\
f(w) \hspace{1em} \text{if} \hspace{1em} g(w) \le 0
\end{cases}
\end{align*}\]</span> As the Lagrange function is equal to <span class="math inline">\(f(w)\)</span> where <span class="math inline">\(g(w) \le 0\)</span>, we can rewrite our original function as, <span class="math display">\[\begin{align*}
\min_w f(w) &amp;= \min_w \left [ \max_{\alpha\ge0} \mathcal{L}(w, \alpha) \right ] \\
&amp;= \min_w \left [ \max_{\alpha\ge0} f(w) + \alpha g(w) \right ] \\
\end{align*}\]</span> In general, we cannot swap the min and max functions unless all the functions involved are convex functions. Hence, as both <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are convex functions in our example, we can rewrite them as follows, <span class="math display">\[
\min_w \left [ \max_{\alpha\ge0} f(w) + \alpha g(w) \right ] \equiv \max_{\alpha\ge0} \left [ \min_w f(w) + \alpha g(w) \right ]
\]</span> Let’s rewrite the above constrained optimization problem with <span class="math inline">\(m\)</span> constraints <span class="math inline">\(g_i(w) \le 0\)</span> where <span class="math inline">\(i \in [1, m]\)</span>. This can written as, <span class="math display">\[\begin{align*}
\min_w f(w) &amp;\equiv \min_w \left [ \max_{\alpha\ge0} f(w) + \sum _{i=1} ^m \alpha _i g_i(w) \right ] \\
&amp;\equiv \max_{\alpha\ge0} \left [ \min_w f(w) + \sum _{i=1} ^m \alpha _i g_i(w) \right ] \\
\end{align*}\]</span></p>
</section>
<section id="formulating-the-dual-problem" class="level1">
<h1>Formulating the Dual Problem</h1>
<p>Our Objective function is as follows, <span class="math display">\[
\min_{w}  \frac{1}{2}||w||^2_2 \quad s.t. (w^Tx_i)y_i \ge 1 \quad \forall i
\]</span> The constraints can be written as follows, <span class="math display">\[\begin{align*}
(w^Tx_i)y_i &amp;\ge 1 \quad \forall i \\
1 - (w^Tx_i)y_i &amp;\le 0 \quad \forall i \\
\end{align*}\]</span> Let <span class="math inline">\(\alpha \in \mathbb{R}^d\)</span> be the Lagrange multipliers, and let our Lagrange function be written as, <span class="math display">\[\begin{align*}
\mathcal{L}(w, \alpha) &amp;= \frac{1}{2}||w||^2_2 + \sum _{i=1} ^n \alpha _i (1 - (w^Tx_i)y_i) \\
\min_w \max_{\alpha\ge0} \left [ \frac{1}{2}||w||^2_2 + \sum _{i=1} ^n \alpha _i (1 - (w^Tx_i)y_i) \right ] &amp;\equiv \max_{\alpha\ge0} \min_w \left [ \frac{1}{2}||w||^2_2 + \sum _{i=1} ^n \alpha _i (1 - (w^Tx_i)y_i) \right ]
\end{align*}\]</span> Solving for the inner function of the dual problem, we get, <span class="math display">\[\begin{align*}
w_{\alpha}^* - \sum _{i=1} ^n \alpha _i x_i y_i = 0 \\
\therefore w_{\alpha}^* = \sum _{i=1} ^n \alpha _i x_i y_i
\end{align*}\]</span> Rewriting the above equation in vectorized form, we get, <span class="math display">\[
w_{\alpha}^* = XY\alpha \quad \ldots[1]
\]</span> where <span class="math inline">\(X \in \mathbb{R}^{d \times n}\)</span>, <span class="math inline">\(Y \in \mathbb{R}^{n \times n}\)</span>, and <span class="math inline">\(\alpha \in \mathbb{R}^{n}\)</span>. <span class="math inline">\(X\)</span> is the dataset, <span class="math inline">\(Y\)</span> is the label diagonal matrix, where the diagonals are the labels. Rewriting the outer dual function, we get, <span class="math display">\[\begin{align*}
&amp;\max_{\alpha\ge0} \left[ \frac{1}{2}||w||^2_2 + \sum _{i=1} ^n \alpha _i (1 - (w^Tx_i)y_i) \right] \\
&amp;= \max_{\alpha\ge0} \left[ \frac{1}{2}w^Tw + \sum _{i=1} ^n \alpha_i -  w^TXY\alpha \right] \\
&amp;= \max_{\alpha\ge0} \left[ \frac{1}{2}(XY\alpha)^TXY\alpha + \sum _{i=1} ^n \alpha_i -  (XY\alpha)^TXY\alpha \right] \quad \ldots\text{from }[1] \\
&amp;= \max_{\alpha\ge0} \left[ \frac{1}{2}\alpha^TY^TX^TXY\alpha + \sum _{i=1} ^n \alpha_i -  \alpha^TY^TX^TXY\alpha \right] \\
&amp;= \max_{\alpha\ge0} \left[\sum _{i=1} ^n \alpha_i -  \frac{1}{2}\alpha^TY^TX^TXY\alpha \right] \\
\end{align*}\]</span></p>
<p><strong>Observations</strong>:</p>
<ol type="1">
<li>As the dual problem solves for <span class="math inline">\(\alpha \ge 0\)</span>, its variable dimension is in <span class="math inline">\(\mathbb{R}^n_+\)</span>, while as the primal problem solves for <span class="math inline">\(w\)</span>, its variable dimension is in <span class="math inline">\(\mathbb{R}^d\)</span>.</li>
<li>Solving the dual problem is “easier”.</li>
<li>As the dual problem depends on <span class="math inline">\(X^TX\)</span>, it can be kernalized.</li>
</ol>
<p>Some observations regarding the following equation, <span class="math display">\[
w_{\alpha}^* = \sum _{i=1} ^n \alpha _i x_i y_i
\]</span></p>
<ol type="1">
<li>The optimal <span class="math inline">\(w^*\)</span> is the linear combination of the datapoints where the importance of each datapoint is given by <span class="math inline">\(\alpha_i\)</span> for the <span class="math inline">\(i^{th}\)</span> point.</li>
<li>Hence, there are points that are more important that others.</li>
</ol>
</section>
<section id="support-vector-machine" class="level1">
<h1>Support Vector Machine</h1>
<p>Revisiting the Lagrangian function, <span class="math display">\[
\min_w \left [ \max_{\alpha\ge0} f(w) + \alpha g(w) \right ] \equiv \max_{\alpha\ge0} \left [ \min_w f(w) + \alpha g(w) \right ]
\]</span> The primal function is represented on the left-hand side of the equation, while the right-hand side represents the dual function. <span class="math inline">\(w^∗\)</span> and <span class="math inline">\(\alpha^*\)</span> are the solutions derived for the primal and dual functions, respectively. When these solutions are inserted into the equation, we obtain, <span class="math display">\[
\max_{\alpha\ge0} f(w^*) + \alpha g(w^*) =  \min_w f(w) + \alpha^* g(w)
\]</span> But as <span class="math inline">\(g(w^*) \le 0\)</span>, the left hand side equates to <span class="math inline">\(f(w^*)\)</span>. <span class="math display">\[
f(w^*) =  \min_w f(w) + \alpha^* g(w)
\]</span> Substituting <span class="math inline">\(w^*\)</span> for <span class="math inline">\(w\)</span> in the right-hand side of the equation would result in a new right-hand side that is greater than or equal to the current one. <span class="math display">\[
f(w^*) \le f(w^*) + \alpha^* g(w^*)
\]</span> <span class="math display">\[
\therefore \alpha^* g(w^*) \ge 0 \quad \ldots [1]
\]</span> But, according to our constraints, <span class="math inline">\(\alpha^* \ge 0\)</span> and <span class="math inline">\(g(w^*)\le0\)</span>. <span class="math display">\[
\therefore \alpha^* g(w^*) \le 0 \quad \ldots [2]
\]</span> From <span class="math inline">\([1]\)</span> and <span class="math inline">\([2]\)</span>, we get, <span class="math display">\[
\alpha^* g(w^*) = 0
\]</span> Rewriting the equation for multiple constraints, we get, <span class="math display">\[
\alpha_i^* g(w^*_i) = 0 \quad \forall i
\]</span> Therefore, if one of the two is greater than zero, the other equals zero. We know that <span class="math inline">\(g(w^*) = 1-(w^Tx_i)y_i\)</span>. <span class="math display">\[
\alpha_i^* (1-(w^Tx_i)y_i) = 0 \quad \forall i
\]</span> As the importance of the <span class="math inline">\(i^{th}\)</span> datapoint is given by <span class="math inline">\(\alpha_i\)</span>, if <span class="math inline">\(\alpha_i &gt; 0\)</span>, we get, <span class="math display">\[
(w^Tx_i)y_i = 1
\]</span> which means that the <span class="math inline">\(i^{th}\)</span> datapoint lies on the <strong>“Supporting”</strong> hyperplane and contributes to <span class="math inline">\(w^*\)</span>.</p>
<p>Therefore, the datapoints whose <span class="math inline">\(\alpha_i &gt; 0\)</span> are known as <strong>Support Vectors</strong> and this algorithm is known as <strong>Support Vector Machine</strong>.</p>
<p><strong>Support Vector Machines (SVMs)</strong> are a type of supervised learning algorithm used for classification and regression analysis. SVMs aim to find the optimal hyperplane that separates data points from different classes with the maximum margin. In the case of non-linearly separable data, SVMs use kernel functions to transform the data into a higher-dimensional space, where a linear decision boundary can be used to separate the data.</p>
<p><strong>Insight</strong>: <span class="math inline">\(w^*\)</span> is a sparse linear combination of the data points.</p>
<section id="hard-margin-svm-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="hard-margin-svm-algorithm">Hard-Margin SVM Algorithm</h2>
<p>This algorithm only works if the dataset is linearly separable with a <span class="math inline">\(\gamma &gt; 0\)</span>.</p>
<ol type="1">
<li>Calculate <span class="math inline">\(Q=X^TX\)</span> directly or using a kernel as per the dataset.</li>
<li>Use the gradient of the dual formula (<span class="math inline">\(\alpha^T1 - \frac{1}{2}\alpha^TY^TQY\alpha\)</span>), in the gradient descent algorithm to find a satisfactory <span class="math inline">\(\alpha\)</span>. Let the intial <span class="math inline">\(\alpha\)</span> be a zero vector <span class="math inline">\(\in \mathbb{R}^n_+\)</span>.</li>
<li>To predict:
<ul>
<li>For non-kernelized SVM: <span class="math inline">\(\text{label}(x_{test}) = w^Tx_{test} = \sum _{i=1} ^n \alpha _i y_i(x_i^Tx_{test})\)</span></li>
<li>For kernelized SVM: <span class="math inline">\(\text{label}(x_{test}) = w^T\phi(x_{test}) = \sum _{i=1} ^n \alpha _i y_ik(x_i^Tx_{test})\)</span></li>
</ul></li>
</ol>
</section>
</section>
<section id="soft-margin-svm" class="level1">
<h1>Soft-Margin SVM</h1>
<p><strong>Soft-Margin SVM</strong> is an extension of the standard SVM algorithm that allows for some misclassifications in the training data. This is useful when the data is not linearly separable, as it allows the SVM to still find a decision boundary that separates the classes as best as possible while allowing for some errors. The degree to which misclassifications are allowed is controlled by a regularization parameter(<span class="math inline">\(C\)</span>), which is used to balance the trade-off between maximizing the margin and minimizing the number of misclassifications.</p>
<p>The primal formulation for this is given by, <span class="math display">\[
\min_{w, \epsilon}  \frac{1}{2}||w||^2_2 + C\sum _{i=1} ^n\epsilon_i \quad s.t. (w^Tx_i)y_i + \epsilon_i \ge 1 \quad \forall i
\]</span> where <span class="math inline">\(C\)</span> is the hyperparameter that is used to balance the trade-off between maximizing the margin and minimizing the number of misclassifications, and <span class="math inline">\(\epsilon_i\)</span> is the additional value required to satisy the constraints.</p>
</section>
<section id="credits" class="level1">
<h1>Credits</h1>
<p>Professor Arun Rajkumar: The content as well as the notations are from his slides and lecture.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>