<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MLT Notes - Supervised Learning - Regression - Ridge/LASSO</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Supervised Learning - Regression - Ridge/LASSO</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">MLT Notes</a> 
        <div class="sidebar-tools-main">
    <a href="https://www.linkedin.com/in/sherry-thomassp/" title="" class="sidebar-tool px-1"><i class="bi bi-linkedin"></i></a>
    <a href="https://github.com/SherryS997/MLT_notes" title="" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Home</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Content</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../about.html" class="sidebar-item-text sidebar-link">About</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Notes</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk01.html" class="sidebar-item-text sidebar-link">Week-01</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk02.html" class="sidebar-item-text sidebar-link">Week-02</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk03.html" class="sidebar-item-text sidebar-link">Week-03</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk04.html" class="sidebar-item-text sidebar-link">Week-04</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk05.html" class="sidebar-item-text sidebar-link">Week-05</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk06.html" class="sidebar-item-text sidebar-link active">Week-06</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk07.html" class="sidebar-item-text sidebar-link">Week-07</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk08.html" class="sidebar-item-text sidebar-link">Week-08</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk09.html" class="sidebar-item-text sidebar-link">Week-09</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#goodness-of-maximum-likelihood-estimator-for-linear-regression" id="toc-goodness-of-maximum-likelihood-estimator-for-linear-regression" class="nav-link active" data-scroll-target="#goodness-of-maximum-likelihood-estimator-for-linear-regression">Goodness of Maximum Likelihood Estimator for Linear Regression</a></li>
  <li><a href="#cross-validation-for-minimizing-mse" id="toc-cross-validation-for-minimizing-mse" class="nav-link" data-scroll-target="#cross-validation-for-minimizing-mse">Cross-Validation for Minimizing MSE</a></li>
  <li><a href="#bayesian-modeling" id="toc-bayesian-modeling" class="nav-link" data-scroll-target="#bayesian-modeling">Bayesian Modeling</a></li>
  <li><a href="#ridge-regression" id="toc-ridge-regression" class="nav-link" data-scroll-target="#ridge-regression">Ridge Regression</a></li>
  <li><a href="#lasso-regression" id="toc-lasso-regression" class="nav-link" data-scroll-target="#lasso-regression">Lasso Regression</a></li>
  <li><a href="#credits" id="toc-credits" class="nav-link" data-scroll-target="#credits">Credits</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Supervised Learning - Regression - Ridge/LASSO</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>PDF Link: <a href="../notes/Wk06.pdf">notes</a></p>
<section id="goodness-of-maximum-likelihood-estimator-for-linear-regression" class="level1">
<h1>Goodness of Maximum Likelihood Estimator for Linear Regression</h1>
<p>Given a dataset <span class="math inline">\(\{x_1, \ldots, x_n\}\)</span> where <span class="math inline">\(x_i \in \mathbb{R}^d\)</span>, let <span class="math inline">\(\{y_1, \ldots, y_n\}\)</span> be the labels, where <span class="math inline">\(y_i \in \mathbb{R}\)</span>. <span class="math display">\[
y|X = w^Tx + \epsilon
\]</span> where <span class="math inline">\(\epsilon \sim \mathcal{N}(0,\sigma^2)\)</span> and <span class="math inline">\(w \in \mathbb{R}^d\)</span>. Let <span class="math inline">\(\hat{w}_{ML}\)</span> signify the maximum likelihood parameter for linear regression. <span class="math display">\[
\hat{w}_{ML}=w^*=(XX^T)^+Xy
\]</span> <span class="math inline">\(\therefore\)</span> To measure how good our parameter is, we use the follow: <span class="math display">\[
\mathbb{E} [|| \hat{w}_{ML} - w ||^2_2]
\]</span> This is known as the Mean Squared Error (MSE) and turns out to be equal to <span class="math display">\[
\mathbb{E} [|| \hat{w}_{ML} - w ||^2_2] = \sigma^2 *trace((XX^T)^{-1})
\]</span></p>
</section>
<section id="cross-validation-for-minimizing-mse" class="level1">
<h1>Cross-Validation for Minimizing MSE</h1>
<p>Let the eigenvalues of <span class="math inline">\(XX^T\)</span> be <span class="math inline">\(\{\lambda_1, \ldots, \lambda_d\}\)</span>. Hence the eigenvalues of <span class="math inline">\((XX^T)^{-1}\)</span> are <span class="math inline">\(\{\frac{1}{\lambda_1}, \ldots, \frac{1}{\lambda_d}\}\)</span>.</p>
<p><span class="math inline">\(\therefore\)</span> The MSE is, <span class="math display">\[
\mathbb{E} [|| \hat{w}_{ML} - w ||^2_2] = \sigma^2 \sum_{i=1}^d  \frac{1}{\lambda_i}
\]</span> Consider the following estimator, <span class="math display">\[
\hat{w}_{new}=(XX^T + \lambda I)^{-1}Xy
\]</span> where <span class="math inline">\(\lambda \in \mathbb{R}\)</span> and <span class="math inline">\(I \in \mathbb{R}^{d\times d}\)</span> is the Identity Matrix. Using this we get, <span class="math display">\[
trace((XX^T + \lambda I)^{-1}) = \sum_{i=1}^d  \frac{1}{\lambda_i + \lambda}
\]</span> According to the Existence Theorem, <span class="math inline">\(\exists\lambda\)</span> s.t. <span class="math inline">\(\hat{w}_{new}\)</span> has lesser means square error than <span class="math inline">\(\hat{w}_{ML}\)</span>.</p>
<p>In practice, we find <span class="math inline">\(\lambda\)</span> using <strong>cross validation</strong>.</p>
<p>Three popular techniques of Cross Validation are:</p>
<ol type="1">
<li><strong>Training-Validation Split</strong>: The training set is randomly split into training and validation set, usually in the ratio <span class="math inline">\(80:20\)</span>. From among various <span class="math inline">\(\lambda\)</span>s, we choose the one with gives the least error.</li>
<li><strong>K-Fold Cross Validation</strong>: It is done by dividing the training set into K equally-sized parts, training the model K times on different (K-1) parts, and evaluating it on the remaining part. From among various <span class="math inline">\(\lambda\)</span>s, we choose the one with gives the least average error.</li>
<li><strong>Leave One Out Cross Validation</strong>: It is done by training the model on all but one of the samples in the training set and evaluating it on the left-out sample, repeating this process for each sample in the dataset. From among various <span class="math inline">\(\lambda\)</span>s, we choose the one with gives the least average error.</li>
</ol>
</section>
<section id="bayesian-modeling" class="level1">
<h1>Bayesian Modeling</h1>
<p>An alternate way to understand <span class="math inline">\(\hat{w}_{ML}\)</span> is through Bayesian Modeling.</p>
<p>Let <span class="math inline">\(P(y|X)\sim \mathcal{N}(w^Tx,I)\)</span>. We use <span class="math inline">\(I\)</span>, the identity matrix, instead of <span class="math inline">\(\sigma^2\)</span> for simplicity.</p>
<p>A good choice of prior for <span class="math inline">\(w\)</span> is <span class="math inline">\(\mathcal{N}(0,\gamma^2I)\)</span>, where <span class="math inline">\(\gamma\in\mathbb{R}^d\)</span>.</p>
<p>Therefore, we get, <span class="math display">\[\begin{align*}
P(w|\{(x_1, y_1), \ldots, (x_n,y_n)\})&amp;\propto P(\{(x_1, y_1), \ldots, (x_n,y_n)\}|w)*P(w)\\
&amp;\propto \left ( \prod _{i=1} ^n e^{\frac{-(y_i - w^Tx_i)^2}{2}}  \right ) * \left ( \prod _{i=1} ^d  e^{\frac{-(w_i - 0)^2}{2\gamma^2}} \right )\\
&amp;\propto \left ( \prod _{i=1} ^n e^{\frac{-(y_i - w^Tx_i)^2}{2}}  \right ) * \left ( e^{-\sum _{i=1} ^d\frac{w_i^2}{2\gamma^2}} \right ) \\
&amp;\propto \left ( \prod _{i=1} ^n e^{\frac{-(y_i - w^Tx_i)^2}{2}}  \right ) * e^{\frac{-||w||^2}{2\gamma^2}} \\
\log(P(w|\{(x_1, y_1), \ldots, (x_n,y_n)\}))&amp;\propto \frac{-(y_i - w^Tx_i)^2}{2}-\frac{||w||^2}{2\gamma^2}
\end{align*}\]</span> <span class="math display">\[
\text{Taking the gradient, we get}
\]</span> <span class="math display">\[\begin{align*}
\nabla \log(P(w|\{(x_1, y_1), \ldots, (x_n,y_n)\}))&amp;\propto  (XX^T)\hat{w}_{MAP} - Xy + \frac{\hat{w}_{MAP}}{\gamma^2} \\
\therefore \hat{w}_{MAP}&amp;=(XX^T + \frac{1}{\gamma^2} I)^{-1}Xy
\end{align*}\]</span> where <span class="math inline">\(\hat{w}_{MAP}\)</span> is the Maximum a posteriori Estimate. In practice, the value for <span class="math inline">\(\frac{1}{\gamma^2}\)</span> is acquired using cross validation.</p>
<p>Hence, Maximum a posteriori Estimation for linear regression with a Gaussian Prior <span class="math inline">\(\mathcal{N}(0,\gamma^2I)\)</span> for <span class="math inline">\(w\)</span> is equivalent to the “new” estimator we used previously.</p>
</section>
<section id="ridge-regression" class="level1">
<h1>Ridge Regression</h1>
<p>Ridge regression is a type of linear regression that adds a penalty term to the ordinary least squares method to mitigate multicollinearity and overfitting.</p>
<p>Its objective function is given by, <span class="math display">\[
\min_{w\in \mathbb{R}^d} \sum^n_{i=1}(w^Tx_i-y_i)^2 + \lambda||w||_2^2
\]</span> where <span class="math inline">\(\lambda||w||_2^2\)</span> is the regularizer, and <span class="math inline">\(||w||_2^2\)</span> is the squared L2 Norm of <span class="math inline">\(w\)</span>. Let this equation be given by <span class="math inline">\(f(w)\)</span>.</p>
<p>Subsequently, this is also equivalent to, <span class="math display">\[
\min_{w\in \mathbb{R}^d} \sum^n_{i=1}(w^Tx_i-y_i)^2 \hspace{1em}\text{s.t.}||w||_2^2\le\theta
\]</span> where <span class="math inline">\(\theta\)</span> is dependent on <span class="math inline">\(\lambda\)</span>.</p>
<p>In conclusion, for every choice of <span class="math inline">\(\lambda&gt;0\)</span>, <span class="math inline">\(\exists \theta\)</span> s.t. there are optimal solutions to our objective function.</p>
<p>The loss function of the linear regression of <span class="math inline">\(w_{ML}\)</span> is given by, <span class="math display">\[
f(w_{ML}) = \sum^n_{i=1}(w_{ML}^Tx_i-y_i)^2
\]</span> Consider the set of all <span class="math inline">\(w\)</span> s.t. <span class="math inline">\(f(w_{ML}) = f(w) + c\)</span> where <span class="math inline">\(c&gt;0\)</span>. This set is given by, <span class="math display">\[
S_c = \left \{w: f(w_{ML}) = f(w) + c \right \}
\]</span> i.e.&nbsp;every <span class="math inline">\(w \in S_c\)</span> satisfies, <span class="math display">\[
||X^Tw-y||^2=||X^Tw_{ML}-y||^2 + c
\]</span> <span class="math display">\[
\text{On Simplification, we get}
\]</span> <span class="math display">\[
(w-w_{ML})^T(XX^T)(w-w_{ML}) = c'
\]</span> where <span class="math inline">\(c'\)</span> depends on <span class="math inline">\(c,XX^T,\)</span> and <span class="math inline">\(w_{ML}\)</span>, but <strong>not on</strong> <span class="math inline">\(w\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/ridge_regression.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Pictoral Representation of what Ridge Regression does.</figcaption><p></p>
</figure>
</div>
<p><strong>Conclusion</strong>: Ridge Regression pushes feature values to zero but not necessarily zero.</p>
</section>
<section id="lasso-regression" class="level1">
<h1>Lasso Regression</h1>
<p><strong>Lasso (Least Absolute Shrinkage and Selection Operator)</strong> regression is a type of linear regression that uses a regularization technique to shrink the coefficients of the less important features to zero, effectively performing feature selection and preventing overfitting.</p>
<p>Its objective function is given by, <span class="math display">\[
\min_{w\in \mathbb{R}^d} \sum^n_{i=1}(w^Tx_i-y_i)^2 + \lambda||w||_1^2
\]</span></p>
<p>As you can see, it is almost the same as Ridge Regression. The only difference is that it uses <span class="math inline">\(||w||_1^2\)</span>, instead of <span class="math inline">\(||w||_2^2\)</span>, which is the squared L1 norm of <span class="math inline">\(w\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/lasso_regression.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Pictoral Representation of what Lasso Regression does.</figcaption><p></p>
</figure>
</div>
<p>Lasso Regression does not have a closed form solution and is often solved using Sub-gradients. For further info on sub-gradients, see <a href="https://see.stanford.edu/materials/lsocoee364b/01-subgradients_notes.pdf">here</a>.</p>
<p><strong>Conclusion</strong>: Lasso Regression pushes less important features to zero.</p>
</section>
<section id="credits" class="level1">
<h1>Credits</h1>
<p>Professor Arun Rajkumar: The content as well as the notations are from his slides and lecture.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>