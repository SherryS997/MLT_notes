<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MLT Notes - Supervised Learning - Classification - Generative Models - Naive Bayes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../pages/Wk09.html" rel="next">
<link href="../pages/Wk07.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../pages/Wk01.html">Notes</a></li><li class="breadcrumb-item"><a href="../pages/Wk08.html">Week-08</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">MLT Notes</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/bsc-iitm/MLT_notes" rel="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Home</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Content</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week-01</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week-02</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week-03</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week-04</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week-05</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week-06</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week-07</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk08.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Week-08</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week-09</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/Wk10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week-10</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#generative-model-based-algorithm" id="toc-generative-model-based-algorithm" class="nav-link active" data-scroll-target="#generative-model-based-algorithm">Generative Model Based Algorithm</a>
  <ul class="collapse">
  <li><a href="#alternate-generative-model" id="toc-alternate-generative-model" class="nav-link" data-scroll-target="#alternate-generative-model">Alternate Generative Model</a></li>
  </ul></li>
  <li><a href="#naive-bayes-algorithm" id="toc-naive-bayes-algorithm" class="nav-link" data-scroll-target="#naive-bayes-algorithm">Naive Bayes Algorithm</a>
  <ul class="collapse">
  <li><a href="#prediction-using-the-parameters" id="toc-prediction-using-the-parameters" class="nav-link" data-scroll-target="#prediction-using-the-parameters">Prediction using the parameters</a></li>
  <li><a href="#pitfalls-of-naive-bayes" id="toc-pitfalls-of-naive-bayes" class="nav-link" data-scroll-target="#pitfalls-of-naive-bayes">Pitfalls of Naive Bayes</a></li>
  </ul></li>
  <li><a href="#decision-function-of-naive-bayes" id="toc-decision-function-of-naive-bayes" class="nav-link" data-scroll-target="#decision-function-of-naive-bayes">Decision Function of Naive Bayes</a></li>
  <li><a href="#gaussian-naive-bayes" id="toc-gaussian-naive-bayes" class="nav-link" data-scroll-target="#gaussian-naive-bayes">Gaussian Naive Bayes</a>
  <ul class="collapse">
  <li><a href="#prediction-using-bayes-rule" id="toc-prediction-using-bayes-rule" class="nav-link" data-scroll-target="#prediction-using-bayes-rule">Prediction using Bayes’ Rule</a></li>
  <li><a href="#decision-boundaries-for-different-covariances" id="toc-decision-boundaries-for-different-covariances" class="nav-link" data-scroll-target="#decision-boundaries-for-different-covariances">Decision Boundaries for Different Covariances</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Supervised Learning - Classification - Generative Models - Naive Bayes</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Feedback/Correction: <a href="https://forms.gle/LehGfBWFX3yWFDBH6">Click here!</a>.</p>
</div>
</div>
<p>PDF Link: <a href="../notes/Wk08.pdf">Click here!</a></p>
<section id="generative-model-based-algorithm" class="level1">
<h1>Generative Model Based Algorithm</h1>
<p>A Generative Model Based Algorithm is an approach that seeks to model the probability distribution of the input data and generate new samples based on this distribution. The key idea involves learning the joint probability distribution of the features and labels in the training data and utilizing this learned model to make predictions for previously unseen data.</p>
<p>Let us consider a dataset <span class="math inline">\(D=\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n,y_n)\}\)</span>, where <span class="math inline">\(\mathbf{x}_i \in \{0, 1\}^d\)</span> and <span class="math inline">\(y_i \in \{0, 1\}\)</span>.</p>
<p>The general steps of the algorithm are as follows:</p>
<ol type="1">
<li>Decide the labels by tossing a coin with <span class="math inline">\(P(y_i=1)=p\)</span>.</li>
<li>Determine the features using the labels obtained in Step 1 through the conditional probability <span class="math inline">\(P(\mathbf{x}_i|y_i)\)</span>.</li>
</ol>
<p>The parameters in the generative model are defined as follows:</p>
<ol type="1">
<li>Parameter <span class="math inline">\(\hat{p}\)</span> to decide the label: 1</li>
<li>Parameters for <span class="math inline">\(P(\mathbf{x}|y=1)\)</span>: <span class="math inline">\(2^d-1\)</span></li>
<li>Parameters for <span class="math inline">\(P(\mathbf{x}|y=0)\)</span>: <span class="math inline">\(2^d-1\)</span></li>
</ol>
<p>Consequently, the total number of parameters is given by: <span class="math display">\[\begin{align*}
    &amp; = 1 + (2^d-1) + (2^d-1) \\
    &amp; = 1 + 2(2^d-1) \\
    &amp; = 2^{d+1}-1
\end{align*}\]</span></p>
<p><strong>Issues</strong>:</p>
<ol type="1">
<li>Too many parameters, which may lead to overfitting.</li>
<li>The model may not be practically viable due to the assumption made in the generative process.</li>
</ol>
<section id="alternate-generative-model" class="level2">
<h2 class="anchored" data-anchor-id="alternate-generative-model">Alternate Generative Model</h2>
<p>An alternative generative model starts with the class conditional independence assumption, which is a common assumption in various machine learning algorithms. This assumption states that the features of an object are conditionally independent given its class label.</p>
<p>Let us again consider the dataset <span class="math inline">\(D=\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n,y_n)\}\)</span>, with <span class="math inline">\(\mathbf{x}_i \in \{0, 1\}^d\)</span> and <span class="math inline">\(y_i \in \{0, 1\}\)</span>.</p>
<p>The general steps of the algorithm under this alternative model are as follows:</p>
<ol type="1">
<li>Decide the labels by tossing a coin with <span class="math inline">\(P(y_i=1)=p\)</span>.</li>
<li>Determine the features for <span class="math inline">\(\mathbf{x}\)</span> given <span class="math inline">\(y\)</span> using the following conditional probability: <span class="math display">\[
P(\mathbf{x} = [f_1, f_2, \ldots, f_d]|y) = \prod_{i=1}^d(p^{y_i}_i)^{f_i}(1-p^{y_i}_i)^{1-f_i}
\]</span></li>
</ol>
<p>The parameters in this alternative model are as follows:</p>
<ol type="1">
<li>Parameter <span class="math inline">\(\hat{p}\)</span> to decide the label: 1</li>
<li>Parameters for <span class="math inline">\(P(\mathbf{x}|y=1)\)</span>: <span class="math inline">\(d\)</span></li>
<li>Parameters for <span class="math inline">\(P(\mathbf{x}|y=0)\)</span>: <span class="math inline">\(d\)</span></li>
</ol>
<p>Thus, the total number of parameters is given by: <span class="math display">\[\begin{align*}
    &amp; = 1 + d + d \\
    &amp; = 2d + 1
\end{align*}\]</span></p>
<p>The parameters are estimated using Maximum Likelihood Estimation.</p>
</section>
</section>
<section id="naive-bayes-algorithm" class="level1">
<h1>Naive Bayes Algorithm</h1>
<p>The Naive Bayes algorithm is a classification algorithm based on Bayes’ theorem, which assumes that the features are independent of each other given the class label. The model calculates the probability of a sample belonging to a class by estimating the conditional probability of each feature given the class and then combining these probabilities using Bayes’ theorem. Despite its simple assumption, Naive Bayes has been found to perform well in various applications, particularly when the number of features is large but the training data is limited.</p>
<p>The model is given by: <span class="math display">\[
P(\mathbf{x} = [f_1, f_2, \ldots, f_d]|y) = \prod_{i=1}^d(p^{y_i}_i)^{f_i}(1-p^{y_i}_i)^{1-f_i}
\]</span></p>
<p>The parameters to be estimated are <span class="math inline">\(p\)</span>, <span class="math inline">\(\{p^0_1,p^0_2,\ldots,p^0_d\}\)</span>, and <span class="math inline">\(\{p^1_1,p^1_2,\ldots,p^1_d\}\)</span>. Using Maximum Likelihood Estimation, we obtain the following estimates: <span class="math display">\[
\hat{p} = \frac{1}{n}\sum_{i=1}^ny_i
\]</span> <span class="math display">\[\begin{align*}
\hat{p}^y_j &amp; = \frac{\displaystyle \sum_{i=1}^n\mathbb{1}(f^i_j=1,y_i=y)}{\displaystyle \sum_{i=1}^n\mathbb{1}(y_i=y)} \hspace{1em} \text{for all } j \in \{1,2,\ldots,d\},\text{ and } \forall y \in \{0,1\}
\end{align*}\]</span></p>
<section id="prediction-using-the-parameters" class="level2">
<h2 class="anchored" data-anchor-id="prediction-using-the-parameters">Prediction using the parameters</h2>
<p>Given <span class="math inline">\(\mathbf{x}^{test}\in\{0,1\}^d\)</span>, the prediction for <span class="math inline">\(\hat{y}^{test}\)</span> is done using the following criterion:</p>
<p><span class="math display">\[
P(\hat{y}^{test}=1|\mathbf{x}^{test}) \ge P(\hat{y}^{test}=0|\mathbf{x}^{test})
\]</span></p>
<p>If the above inequality holds, then <span class="math inline">\(\hat{y}^{test}=1\)</span>, otherwise <span class="math inline">\(\hat{y}^{test}=0\)</span>.</p>
<p>Using Bayes’ rule, we can express <span class="math inline">\(P(\hat{y}^{test}=1|\mathbf{x}^{test})\)</span> and <span class="math inline">\(P(\hat{y}^{test}=0|\mathbf{x}^{test})\)</span> as follows:</p>
<p><span class="math display">\[\begin{align*}
P(\hat{y}^{test}=1|\mathbf{x}^{test}) &amp; = \frac{P(\mathbf{x}^{test}|\hat{y}^{test}=1)*P(\hat{y}^{test}=1)}{P(\mathbf{x}^{test})} \\
P(\hat{y}^{test}=0|\mathbf{x}^{test}) &amp; = \frac{P(\mathbf{x}^{test}|\hat{y}^{test}=0)*P(\hat{y}^{test}=0)}{P(\mathbf{x}^{test})}
\end{align*}\]</span></p>
<p>However, since we are only interested in the comparison of these probabilities, we can avoid calculating <span class="math inline">\(P(\mathbf{x}^{test})\)</span>.</p>
<p>By solving for <span class="math inline">\(P(\mathbf{x}^{test}|\hat{y}^{test}=1)*P(\hat{y}^{test}=1)\)</span>, we find:</p>
<p><span class="math display">\[\begin{align*}
&amp;=P(\mathbf{x}^{test} = [f_1, f_2, \ldots, f_d]|y^{test}=1)*P(\hat{y}^{test}=1) \\
&amp;=\left(\prod_{i=1}^d(\hat{p}^1_i)^{f_i}(1-\hat{p}^1_i)^{1-f_i}\right)*\hat{p}
\end{align*}\]</span></p>
<p>Similarly, we can obtain <span class="math inline">\(P(\mathbf{x}^{test}|\hat{y}^{test}=0)*P(\hat{y}^{test}=0)\)</span>.</p>
<p>Therefore, we predict <span class="math inline">\(\hat{y}^{test}=1\)</span> if:</p>
<p><span class="math display">\[
\left(\prod_{i=1}^d(\hat{p}^1_i)^{f_i}(1-\hat{p}^1_i)^{1-f_i}\right)*\hat{p} \ge \left(\prod_{i=1}^d(\hat{p}^0_i)^{f_i}(1-\hat{p}^0_i)^{1-f_i}\right)*(1-\hat{p})
\]</span></p>
<p>Otherwise, we predict <span class="math inline">\(\hat{y}^{test}=0\)</span>.</p>
<p>The Naive Bayes algorithm employs two main techniques:</p>
<ol type="1">
<li>The Class Conditional Independence Assumption.</li>
<li>Utilizing Bayes’ Rule.</li>
</ol>
<p>As a result, this algorithm is commonly referred to as Naive Bayes.</p>
<p>In summary, <strong>Naive Bayes</strong> is a classification algorithm based on Bayes’ theorem, which assumes that the features are independent of each other given the class label. It estimates the conditional probabilities of features given the class and uses these probabilities to make predictions for new data. Despite its naive assumption, Naive Bayes has demonstrated good performance across various applications, particularly when dealing with high-dimensional data and limited training examples.</p>
</section>
<section id="pitfalls-of-naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="pitfalls-of-naive-bayes">Pitfalls of Naive Bayes</h2>
<p>One prominent issue with Naive Bayes is that if a feature is not observed in the training set but present in the testing set, the prediction probabilities for both classes become zero.</p>
<p><span class="math display">\[\begin{align*}
P(\hat{y}^{test}=1|\mathbf{x}^{test} = [f_1, f_2, \ldots, f_d]) &amp; \propto \left(\prod_{i=1}^d(\hat{p}^1_i)^{f_i}(1-\hat{p}^1_i)^{1-f_i}\right)*\hat{p} \\
P(\hat{y}^{test}=0|\mathbf{x}^{test} = [f_1, f_2, \ldots, f_d]) &amp; \propto \left(\prod_{i=1}^d(\hat{p}^0_i)^{f_i}(1-\hat{p}^0_i)^{1-f_i}\right)*(1-\hat{p})
\end{align*}\]</span></p>
<p>If any feature <span class="math inline">\(f_i\)</span> was absent in the training set, it results in <span class="math inline">\(\hat{p}^1_i=\hat{p}^0_i=0\)</span>, leading to <span class="math inline">\(P(\hat{y}^{test}=0|\mathbf{x}^{test})=P(\hat{y}^{test}=1|\mathbf{x}^{test})=0\)</span>.</p>
<p>A popular remedy for this issue is to introduce two “pseudo” data points with labels 1 and 0, respectively, into the dataset, where all their features are set to 1. This technique is also known as Laplace smoothing.</p>
<p>In brief, <strong>Laplace smoothing</strong> is a technique employed to address the zero-frequency problem in probabilistic models, particularly in text classification. It involves adding a small constant value to the count of each feature and the number of unique classes to avoid zero probability estimates, which can cause problems during model training and prediction. By incorporating this smoothing term, the model becomes more robust and better suited for handling unseen data.</p>
</section>
</section>
<section id="decision-function-of-naive-bayes" class="level1">
<h1>Decision Function of Naive Bayes</h1>
<p>Given <span class="math inline">\(\mathbf{x}^{test}\in\{0,1\}^d\)</span>, the prediction for <span class="math inline">\(\hat{y}^{test}\)</span> is obtained using the following decision function:</p>
<p><span class="math display">\[\begin{multline*}\\
\frac{P(\hat{y}^{test}=1|\mathbf{x}^{test})}{P(\hat{y}^{test}=0|\mathbf{x}^{test})}\ge 1\\
\log \left (\frac{P(\hat{y}^{test}=1|\mathbf{x}^{test})}{P(\hat{y}^{test}=0|\mathbf{x}^{test})}\right )\ge 0\\
\log \left (\frac{\displaystyle\frac{P(\mathbf{x}^{test}|\hat{y}^{test}=1)*P(\hat{y}^{test}=1)}{P(\mathbf{x}^{test})}}{\displaystyle\frac{P(\mathbf{x}^{test}|\hat{y}^{test}=0)*P(\hat{y}^{test}=0)}{P(\mathbf{x}^{test})}}\right )\ge 0 \\
\log \left (\prod_{i=1}^d\frac{(\hat{p}^1_i)^{f_i}(1-\hat{p}^1_i)^{1-f_i}\hat{p}}{(\hat{p}^0_i)^{f_i}(1-\hat{p}^0_i)^{1-f_i}(1-\hat{p})}\right )\ge 0 \\
\log \left (\prod_{i=1}^d\left(\frac{\hat{p}^1_i}{\hat{p}^0_i}\right)^{f_i}\left(\frac{1-\hat{p}^1_i}{1-\hat{p}^0_i}\right)^{1-f_i}\frac{\hat{p}}{1-\hat{p}}\right )\ge 0 \\
\sum_{i=1}^d \left (f_i\log\left(\frac{\hat{p}^1_i}{\hat{p}^0_i}\right)+(1-f_i)\log\left(\frac{1-\hat{p}^1_i}{1-\hat{p}^0_i}\right)+\log\left(\frac{\hat{p}}{1-\hat{p}}\right)\right )\ge 0 \\
\sum_{i=1}^d \left (f_i\log\left(\frac{\hat{p}^1_i(1-\hat{p}^0_i)}{\hat{p}^0_i(1-\hat{p}^1_i)}\right)\right )+\sum_{i=1}^d\log\left(\frac{1-\hat{p}^1_i}{1-\hat{p}^0_i}\right)+\log\left(\frac{\hat{p}}{1-\hat{p}}\right)\ge 0
\end{multline*}\]</span></p>
<p>Thus, we can express the decision function as <span class="math inline">\(w^T\mathbf{x}+b\ge0\)</span>, where <span class="math inline">\(w\in\mathbb{R}^d\)</span>, <span class="math inline">\(w_i=\displaystyle\log\left(\frac{\hat{p}^1_i(1-\hat{p}^0_i)}{\hat{p}^0_i(1-\hat{p}^1_i)}\right)\)</span>, and <span class="math inline">\(b=\displaystyle\sum_{i=1}^d\log\left(\frac{1-\hat{p}^1_i}{1-\hat{p}^0_i}\right)+\log\left(\frac{\hat{p}}{1-\hat{p}}\right)\)</span>.</p>
<p>Consequently, the decision function of Naive Bayes is <strong>linear</strong>.</p>
<p>The decision boundary is given by <span class="math inline">\(\{\mathbf{x}=P(y=1|\mathbf{x})=P(y=0|\mathbf{x})\}\)</span>.</p>
</section>
<section id="gaussian-naive-bayes" class="level1">
<h1>Gaussian Naive Bayes</h1>
<p>Gaussian Naive Bayes, also known as Gaussian Discriminant Analysis (GDA) or Gaussian Discriminant Analysis Naive Bayes (GDANB), represents a variant of the Naive Bayes algorithm designed for classification tasks. This approach assumes that the features in the dataset follow a Gaussian (normal) distribution and computes the likelihood of a class for a given set of feature values by estimating the mean and variance of the feature values within each class.</p>
<p>Consider a dataset, D, comprising data points in the form of pairs <span class="math inline">\(\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n,y_n)\}\)</span>, where <span class="math inline">\(\mathbf{x}_i \in \mathbb{R}^d\)</span> represents the feature vector and <span class="math inline">\(y_i \in \{0, 1\}\)</span> denotes the class label.</p>
<p>Let <span class="math inline">\(P(\mathbf{x}|y=1)\sim\mathcal{N}(\boldsymbol{\mu}_1,\boldsymbol{\Sigma})\)</span> and <span class="math inline">\(P(\mathbf{x}|y=0)\sim\mathcal{N}(\boldsymbol{\mu}_0,\boldsymbol{\Sigma})\)</span>, with the assumption that the covariance matrices are equal.</p>
<p>To estimate the parameters, we need to find values for <span class="math inline">\(\hat{p}\)</span>, <span class="math inline">\(\boldsymbol{\mu}_0\)</span>, <span class="math inline">\(\boldsymbol{\mu}_1\)</span>, and <span class="math inline">\(\boldsymbol{\Sigma}\)</span>. Using Maximum Likelihood Estimation, we obtain the following results:</p>
<p><span class="math display">\[\begin{align*}
\hat{p} &amp;= \frac{1}{n}\sum_{i=1}^n y_i \\
\hat{\boldsymbol{\mu}}_1 &amp;= \frac{\displaystyle \sum_{i=1}^n \mathbb{1}(y_i=1)*\mathbf{x}_i}{\displaystyle \sum_{i=1}^n \mathbb{1}(y_i=1)} \\
\hat{\boldsymbol{\mu}}_0 &amp;= \frac{\displaystyle \sum_{i=1}^n \mathbb{1}(y_i=0)*\mathbf{x}_i}{\displaystyle \sum_{i=1}^n \mathbb{1}(y_i=0)} \\
\hat{\boldsymbol{\Sigma}} &amp;= \frac{1}{n} \displaystyle \sum_{i=1}^n (\mathbf{x}_i-\hat{\boldsymbol{\mu}}_{y_i})(\mathbf{x}_i-\hat{\boldsymbol{\mu}}_{y_i})^T
\end{align*}\]</span></p>
<p>In the above equations, <span class="math inline">\(\hat{p}\)</span> represents the proportion of data points labeled 1, <span class="math inline">\(\hat{\boldsymbol{\mu}}_1\)</span> is the sample mean of data points labeled 1, <span class="math inline">\(\hat{\boldsymbol{\mu}}_0\)</span> is the sample mean of data points labeled 0, and <span class="math inline">\(\hat{\boldsymbol{\Sigma}}\)</span> is the covariance matrix of the centered dataset.</p>
<section id="prediction-using-bayes-rule" class="level2">
<h2 class="anchored" data-anchor-id="prediction-using-bayes-rule">Prediction using Bayes’ Rule</h2>
<p>Prediction is based on the following equation: <span class="math display">\[
P(y_{test}=1|\mathbf{x}_{test})\propto P(\mathbf{x}_{test}|y_{test})*P(y_{test})
\]</span></p>
<p>Where <span class="math inline">\(P(\mathbf{x}_{test}|y_{test})\equiv f(\mathbf{x}_{test};\hat{\boldsymbol{\mu}}_{y_{test}}, \hat{\boldsymbol{\Sigma}})\)</span> and <span class="math inline">\(P(y_{test})\equiv \hat{p}\)</span>.</p>
<p>To predict <span class="math inline">\(y_{test}=1\)</span>, we compare the probabilities:</p>
<p><span class="math display">\[\begin{align*}
f(\mathbf{x}_{i} ;\hat{\boldsymbol{\mu} }_{1} ,\hat{\boldsymbol{\Sigma} }_{1} )\hat{p} &amp; \geq f(\mathbf{x}_{i} ;\hat{\boldsymbol{\mu} }_{0} ,\hat{\boldsymbol{\Sigma} }_{0} )(1-\hat{p} )\\
e^{-(\mathbf{x}_{i} -\hat{\boldsymbol{\mu} }_{1} )^{T}\hat{\boldsymbol{\Sigma} }_{1}^{-1} (\mathbf{x}_{i} -\hat{\boldsymbol{\mu} }_{1} )}\hat{p} &amp; \geq e^{-(\mathbf{x}_{i} -\hat{\boldsymbol{\mu} }_{0} )^{T}\hat{\boldsymbol{\Sigma} }_{0}^{-1} (\mathbf{x}_{i} -\hat{\boldsymbol{\mu} }_{0} )} (1-\hat{p} )\\
-(\mathbf{x}_{i} -\hat{\boldsymbol{\mu} }_{1} )^{T}\hat{\boldsymbol{\Sigma} }_{1}^{-1} (\mathbf{x}_{i} -\hat{\boldsymbol{\mu} }_{1} )+\log (\hat{p} ) &amp; \geq -(\mathbf{x}_{i} -\hat{\boldsymbol{\mu} }_{0} )^{T}\hat{\boldsymbol{\Sigma} }_{0}^{-1} (\mathbf{x}_{i} -\hat{\boldsymbol{\mu} }_{0} )+\log (1-\hat{p} )
\end{align*}\]</span></p>
<p>This inequality can be expressed as a linear decision function:</p>
<p><span class="math display">\[
\left( (\hat{\boldsymbol{\mu}}_1-\hat{\boldsymbol{\mu}}_0)^T\hat{\boldsymbol{\Sigma}}^{-1} \right)\mathbf{x}_{test} + \hat{\boldsymbol{\mu}}_0^T\hat{\boldsymbol{\Sigma}}^{-1}\hat{\boldsymbol{\mu}}_0 - \hat{\boldsymbol{\mu}}_1^T\hat{\boldsymbol{\Sigma}}^{-1}\hat{\boldsymbol{\mu}}_1 + \log(\frac{1-\hat{p}}{\hat{p}}) \ge 0
\]</span></p>
<p>Thus, the decision function of Gaussian Naive Bayes is <strong>linear</strong>.</p>
</section>
<section id="decision-boundaries-for-different-covariances" class="level2">
<h2 class="anchored" data-anchor-id="decision-boundaries-for-different-covariances">Decision Boundaries for Different Covariances</h2>
<ol type="1">
<li><strong>When the covariance matrices are equal for both classes</strong>: As previously discussed, the decision boundary is linear.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/equal_var.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">When the covariance matrices are equal for both classes</figcaption>
</figure>
</div>
<ol start="2" type="1">
<li><strong>When the covariance matrices are Identity matrices for both classes</strong>: The decision boundary is both linear and the perpendicular bisector of the line drawn from <span class="math inline">\(\hat{\boldsymbol{\mu}}_1\)</span> to <span class="math inline">\(\hat{\boldsymbol{\mu}}_0\)</span>.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/identity_var.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">When the covariance matrices are Identity matrices for both classes</figcaption>
</figure>
</div>
<ol start="3" type="1">
<li><strong>When the covariance matrices are not equal for both classes</strong>: Let <span class="math inline">\(\hat{\boldsymbol{\Sigma}}_1\)</span> and <span class="math inline">\(\hat{\boldsymbol{\Sigma}}_0\)</span> be the covariance matrices for classes 1 and 0, respectively. They are given by, <span class="math display">\[\begin{align*}
\hat{\boldsymbol{\Sigma}}_1 &amp;= \frac{\displaystyle \sum_{i=1}^n(\mathbb{1}(y_i=1)*\mathbf{x}_i-\hat{\boldsymbol{\mu}}_1)(\mathbb{1}(y_i=1)*\mathbf{x}_i-\hat{\boldsymbol{\mu}}_1)^T}{\displaystyle \sum_{i=1}^n\mathbb{1}(y_i=1)} \\
\hat{\boldsymbol{\Sigma}}_0 &amp;= \frac{\displaystyle \sum_{i=1}^n(\mathbb{1}(y_i=0)*\mathbf{x}_i-\hat{\boldsymbol{\mu}}_0)(\mathbb{1}(y_i=0)*\mathbf{x}_i-\hat{\boldsymbol{\mu}}_0)^T}{\displaystyle \sum_{i=1}^n\mathbb{1}(y_i=0)}
\end{align*}\]</span> To predict <span class="math inline">\(y_{test}=1\)</span>, we compare the probabilities: <span class="math display">\[\begin{align*}
f(\mathbf{x}_{test};\hat{\boldsymbol{\mu}}_1, \hat{\boldsymbol{\Sigma}}_1)*\hat{p}&amp;\ge f(\mathbf{x}_{test};\hat{\boldsymbol{\mu}}_0, \hat{\boldsymbol{\Sigma}}_0)*(1-\hat{p}) \\
e^{-(\mathbf{x}_{test}-\hat{\boldsymbol{\mu}}_1)^T\hat{\boldsymbol{\Sigma}}_1(\mathbf{x}_{test}-\hat{\boldsymbol{\mu}}_1)}*\hat{p}&amp;\ge e^{-(\mathbf{x}_{test}-\hat{\boldsymbol{\mu}}_0)^T\hat{\boldsymbol{\Sigma}}_1(\mathbf{x}_{test}-\hat{\boldsymbol{\mu}}_0)}*(1-\hat{p}) \\
-(\mathbf{x}_{test}-\hat{\boldsymbol{\mu}}_1)^T\hat{\boldsymbol{\Sigma}}_1(\mathbf{x}_{test}-\hat{\boldsymbol{\mu}}_1)+\log(\hat{p})&amp;\ge -(\mathbf{x}_{test}-\hat{\boldsymbol{\mu}}_0)^T\hat{\boldsymbol{\Sigma}}_0(\mathbf{x}_{test}-\hat{\boldsymbol{\mu}}_0) + \log(1-\hat{p}) \\
\end{align*}\]</span> This inequality leads to a quadratic decision function: <span class="math display">\[
\mathbf{x}_{test}^T(\hat{\boldsymbol{\Sigma}}_1^{-1}-\hat{\boldsymbol{\Sigma}}_0^{-1})\mathbf{x}_{test}-2(\hat{\boldsymbol{\mu}}_1^T\hat{\boldsymbol{\Sigma}}_1^{-1}-\hat{\boldsymbol{\mu}}_0^T\hat{\boldsymbol{\Sigma}}_0^{-1})\mathbf{x}_{test}+(\hat{\boldsymbol{\mu}}_0^T\hat{\boldsymbol{\Sigma}}_0^{-1}\hat{\boldsymbol{\mu}}_0-\hat{\boldsymbol{\mu}}_1^T\hat{\boldsymbol{\Sigma}}_1^{-1}\hat{\boldsymbol{\mu}}_1) + \log(\frac{1-\hat{p}}{\hat{p}}) \ge 0
\]</span> Hence, the decision boundary is a quadratic function when the covariance matrices are not equal for both classes.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/non-equal_var.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">When the covariance matrices are not equal for both classes</figcaption>
</figure>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../pages/Wk07.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Week-07</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../pages/Wk09.html" class="pagination-link">
        <span class="nav-page-text">Week-09</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>