<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MLT Notes - Supervised Learning - Classification - K-NN, Decision tree</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Supervised Learning - Classification - K-NN, Decision tree</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MLT Notes</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Home</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Content</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about.html" class="sidebar-item-text sidebar-link">About</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Notes</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Wk04.html" class="sidebar-item-text sidebar-link">Week-04</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Wk05.html" class="sidebar-item-text sidebar-link">Week-05</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Wk06.html" class="sidebar-item-text sidebar-link">Week-06</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Wk07.html" class="sidebar-item-text sidebar-link active">Week-07</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-to-binary-classification" id="toc-introduction-to-binary-classification" class="nav-link active" data-scroll-target="#introduction-to-binary-classification">Introduction to Binary Classification</a></li>
  <li><a href="#linear-classifier" id="toc-linear-classifier" class="nav-link" data-scroll-target="#linear-classifier">Linear Classifier</a></li>
  <li><a href="#k-nearest-neighbours-algorithm" id="toc-k-nearest-neighbours-algorithm" class="nav-link" data-scroll-target="#k-nearest-neighbours-algorithm">K-Nearest Neighbours Algorithm</a>
  <ul class="collapse">
  <li><a href="#issues-with-k-nn" id="toc-issues-with-k-nn" class="nav-link" data-scroll-target="#issues-with-k-nn">Issues with K-NN</a></li>
  </ul></li>
  <li><a href="#introduction-to-decision-trees" id="toc-introduction-to-decision-trees" class="nav-link" data-scroll-target="#introduction-to-decision-trees">Introduction to Decision Trees</a>
  <ul class="collapse">
  <li><a href="#goodness-of-a-question" id="toc-goodness-of-a-question" class="nav-link" data-scroll-target="#goodness-of-a-question">Goodness of a Question</a></li>
  <li><a href="#decision-tree-algorithm" id="toc-decision-tree-algorithm" class="nav-link" data-scroll-target="#decision-tree-algorithm">Decision Tree Algorithm</a></li>
  </ul></li>
  <li><a href="#generative-and-discriminative-models" id="toc-generative-and-discriminative-models" class="nav-link" data-scroll-target="#generative-and-discriminative-models">Generative and Discriminative Models</a></li>
  <li><a href="#credits" id="toc-credits" class="nav-link" data-scroll-target="#credits">Credits</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Supervised Learning - Classification - K-NN, Decision tree</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction-to-binary-classification" class="level1">
<h1>Introduction to Binary Classification</h1>
<p>Binary classification is a machine learning task where the goal is to classify objects into one of two categories. It is a fundamental problem in various fields, including computer vision, natural language processing, and bioinformatics.</p>
<p>Given a dataset <span class="math inline">\(\{x_1, \ldots, x_n\}\)</span> where <span class="math inline">\(x_i \in \mathbb{R}^d\)</span>, let <span class="math inline">\(\{y_1, \ldots, y_n\}\)</span> be the labels, where <span class="math inline">\(y_i \in \{0, 1\}\)</span>. The goal is given by <span class="math inline">\(h: \mathbb{R}^d \rightarrow \{0, 1\}\)</span>.</p>
<p>The loss for this function is given by, <span class="math display">\[
loss(h)=\frac{1}{n}\sum ^n _{i=1}\mathbb{1}\left ( h(x_i) \ne y_i \right )
\]</span> Let <span class="math inline">\(\mathcal{H}_{\text{linear}}\)</span> represent the solution space for the mapping in the linear space. <span class="math display">\[
\mathcal{H}_{\text{linear}}=\Biggr \lbrace{h_w: \mathbb{R}^d \rightarrow \{1, 0\} \hspace{0.5em} s.t. \hspace{0.5em} h_w(x)=sign(w^Tx) \hspace{0.5em} \forall w \in \mathbb{R}^d } \Biggr \rbrace
\]</span> Therefore, the objective function is given by, <span class="math display">\[
\min _{h \in \mathcal{H}_{\text{linear}}} \sum _{i=1} ^n \mathbb{1}\left ( h(x_i) \ne y_i \right )
\]</span> This objective function presents an NP-Hard Problem, indicating the challenge in arriving at optimal and sufficient parameters. Therefore, improved implementations are necessary to address this complexity and achieve satisfactory results.</p>
</section>
<section id="linear-classifier" class="level1">
<h1>Linear Classifier</h1>
<p>Can we use linear regression to solve this classification problem?</p>
<p>The proposed algorithm would be as follows: <span class="math display">\[
\{(x_1, y_1), \ldots, (x_n,y_n)\} \xrightarrow[Regression]{Linear} w \in \mathbb{R}^d\rightarrow h_w: \mathbb{R}^d \rightarrow \{1, 0\}
\]</span> But this poses an issue in classification. Look at the diagram below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/lin_class.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Linear classification and the problem due to outliers</figcaption><p></p>
</figure>
</div>
<p>Upon a detailed examination of the above diagram, it is evident that classification based on Linear Regression not only partitions the two categories of data based on their respective sides but also their positions. Consequently, this approach may cause the classification boundary to shift w.r.t. the outliers in the dataset. Therefore, this approach is not feasible.</p>
</section>
<section id="k-nearest-neighbours-algorithm" class="level1">
<h1>K-Nearest Neighbours Algorithm</h1>
<p>The K-Nearest Neighbor (K-NN) algorithm is a popular non-parametric method used for classification and regression tasks in machine learning. It operates by identifying the K-nearest data points to the target object, classifying or regressing the target object based on the majority of its nearest neighbors.</p>
<p>The algorithm is as follows:</p>
<ul>
<li>Given <span class="math inline">\(x_{test}\)</span> find the <span class="math inline">\(k\)</span>-closest points in the training set - <span class="math inline">\(\{x_1^*, x_2^*, \ldots, x_k^*\}\)</span>.</li>
<li>Predict <span class="math inline">\(y_{test} = \text{majority}(y_1^*, y_2^*, \ldots, y_k^*)\)</span></li>
</ul>
<p>Look at the following diagrams to the see the effect of the value of <span class="math inline">\(k\)</span> on the classification:</p>
<p><img src="../images/k1.png" class="img-fluid" alt="k=1"> <span class="math display">\[
\text{When }k=1\text{, the classification is too sensitive to the outliers.}
\]</span> <img src="../images/kn.png" class="img-fluid" alt="k=1"> <span class="math display">\[
\text{When }k=n\text{, the classification is too smooth.}
\]</span> <img src="../images/k_star.png" class="img-fluid" alt="k=k^*"> <span class="math display">\[
\text{When }k=k^*\text{, the classification is just right.}
\]</span> The choice of <span class="math inline">\(k\)</span> is usually done by cross-validation, where <span class="math inline">\(k\)</span> is treated as a hyper-parameter. The smaller <span class="math inline">\(k\)</span> is, the more complex the classification will be.</p>
<section id="issues-with-k-nn" class="level2">
<h2 class="anchored" data-anchor-id="issues-with-k-nn">Issues with K-NN</h2>
<p>Following are the issues with the algorithm:</p>
<ul>
<li>The choice of distance function itself can give different results. The Euclidean distance might not always be the best fit!</li>
<li>It can be computationally demanding. When making a prediction for a single test datapoint, the distances between that datapoint and all training points must be calculated and sorted. As a result, the algorithm has a complexity of <span class="math inline">\(O(nlog(n))\)</span>, where <span class="math inline">\(n\)</span> represents the size of the dataset.</li>
<li>No model is learned by this algorithm. It always needs the training dataset to make proper predictions.</li>
</ul>
</section>
</section>
<section id="introduction-to-decision-trees" class="level1">
<h1>Introduction to Decision Trees</h1>
<p>Decision trees are a popular machine learning algorithm that operates by recursively splitting the data based on the most informative features until a stopping criterion is met. They are widely used for classification and regression tasks and can be visualized as a tree-like structure.</p>
<p>Given a dataset <span class="math inline">\(\{x_1, \ldots, x_n\}\)</span> where <span class="math inline">\(x_i \in \mathbb{R}^d\)</span>, let <span class="math inline">\(\{y_1, \ldots, y_n\}\)</span> be the labels where <span class="math inline">\(y_i \in \{0, 1\}\)</span>. The output of the algorithm will be a decision tree.</p>
<p>Prediction: Given <span class="math inline">\(x_{test}\)</span>, traverse through the tree to reach a leaf node. <span class="math inline">\(y_{test} = \text{value in the leaf node}\)</span>.</p>
<p>Pictorial depiction of the decision tree:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/decision_tree.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Decision Tree</figcaption><p></p>
</figure>
</div>
<p>where a <strong>question</strong> is a (feature, value) pair. Example: <span class="math inline">\(height\le180cm\)</span>?</p>
<section id="goodness-of-a-question" class="level2">
<h2 class="anchored" data-anchor-id="goodness-of-a-question">Goodness of a Question</h2>
<p>Let <span class="math inline">\(D=\{(x_1, y_1), \ldots, (x_n,y_n)\}\)</span> be the dataset. We partition it using a question into <span class="math inline">\(D_{yes}\)</span> and <span class="math inline">\(D_{no}\)</span>.</p>
<p>What we need is a measure of “Impurity” for a set of labels <span class="math inline">\(\{y_1, \ldots, y_n\}\)</span>. This measure can be given by various ways, but we will use the <strong>Entropy</strong> Function.</p>
<p>The Entropy function is given by, <span class="math display">\[
Entropy(\{y_1, \ldots, y_n\}) = Entropy(p) = -\left( p\log(p)+(1-p)\log(1-p) \right )
\]</span> where conventionally <span class="math inline">\(\log(0)\)</span> is treated as <span class="math inline">\(0\)</span>.</p>
<p>Pictorial Representation of the Entropy function:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/entropy.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Entropy Function</figcaption><p></p>
</figure>
</div>
<p>Then, we use Information Gain to measure the goodness of the split.</p>
<p><strong>Information gain</strong> is a commonly used criterion in decision tree algorithms that measures the reduction in entropy or impurity of a dataset after splitting based on a given feature. By selecting features with high information gain, decision trees can effectively differentiate between the different classes of data and make accurate predictions.</p>
<p>Information gain is given by, <span class="math display">\[
\text{Information Gain}(feature,value)=Entropy(D) - \left [ \gamma Entropy(D_{yes})+(1-\gamma)Entropy(D_{no}) \right ]
\]</span> where <span class="math inline">\(\gamma\)</span> is given by, <span class="math display">\[
\gamma=\frac{|D_{yes}|}{|D|}
\]</span></p>
</section>
<section id="decision-tree-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="decision-tree-algorithm">Decision Tree Algorithm</h2>
<p>The algorithm is as follows:</p>
<ul>
<li>Discretize each feature in [min,max] range.</li>
<li>Pick the question that has the largest information gain.</li>
<li>Repeat the procedure for <span class="math inline">\(D_{yes}\)</span> and <span class="math inline">\(D_{no}\)</span>.</li>
<li>Stop growing the tree if a node becomes sufficiently “pure”.</li>
</ul>
<p>The goodness of a question can also be measured using different methods like the Gini Index, etc.</p>
<p>Pictorial Depiction of decision boundary and its decision tree:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/decision_bound.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Decision Boundary</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="generative-and-discriminative-models" class="level1">
<h1>Generative and Discriminative Models</h1>
<p>For the classical Classification problem, there are two types of modeling: Generative and Discriminative Models.</p>
<p>Generative Models are given by, <span class="math display">\[
P(x,y)
\]</span> This primarily tries to model the feature generation.</p>
<p>Discriminative Models are given by, <span class="math display">\[
P(y|x)
\]</span> This only generates labels based on the data.</p>
</section>
<section id="credits" class="level1">
<h1>Credits</h1>
<p>Professor Arun Rajkumar: The content as well as the notations are from his slides and lecture.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>